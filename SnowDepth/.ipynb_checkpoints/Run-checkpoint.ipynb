{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95459359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Load_ATL03\n",
    "import Surface\n",
    "import Snow_depth\n",
    "import Masking\n",
    "import Rescaling\n",
    "import Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc11271",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sampling in module Sampling:\n",
      "\n",
      "sampling(path, date)\n",
      "    Samples values from Sentinel-1 variables and DEM into rescaled snow depth data\n",
      "    \n",
      "    Input:\n",
      "        path: Path to AOI-folder\n",
      "        date: Folder for date of observation (e.g. 20210211)\n",
      "    \n",
      "    Output:\n",
      "        df_training: A shapefile with training points containing values of Sentinel-1 variables and DEM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sampling.sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd386f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(params):\n",
    "\n",
    "    #datelist = ['20200204','20200206','20200306','20200314','20200406','20200410','20210203','20210205','20210207','20210209','20210211','20210304','20210308']\n",
    "    datelist = ['20210304']\n",
    "    for dates in datelist:\n",
    "        params['date'] = dates\n",
    "        print('started processing of date: ', dates)\n",
    "    \n",
    "    \n",
    "        #beamlist = ['gt1l','gt2l','gt3l','gt1r','gt2r','gt3r']\n",
    "        beamlist = ['gt1l','gt2l']\n",
    "\n",
    "    #    i=0\n",
    "        for ISbeam in beamlist:\n",
    "            params['beam'] = ISbeam\n",
    "            df, geoid = load_ATL03(params['path'],params['date'], params['beam'])\n",
    "            print('ATL03 Dataset loaded')\n",
    "\n",
    "            df_surf = surface(df, 10, geoid, 10)\n",
    "            df_surf = df_surf[df_surf['Surface'] != 0]\n",
    "            print('Surface Heights Estimated')\n",
    "\n",
    "            df_SD = snow_depth(df_surf, params['beam'], params['DEM'])\n",
    "            print('Snow Depths Estimated')\n",
    "\n",
    "            df_Mask = Mask(df_SD, params['path'], params['date'])\n",
    "            print('Masked out training points')\n",
    "\n",
    "            df_RE = Rescale(df_Mask, 3000, 1000, params['beam'], params['path'], params['date'])\n",
    "            print('Rescaled training points')\n",
    "            print('completed ICESat-2 Processing for beam: ',ISbeam)\n",
    "\n",
    "            pts = Sample(params['path'], params['date'])\n",
    "        \n",
    "    return df, df_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d42663",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_params = {\n",
    "    'path' : 'C:/Users/Rasmu/Documents/Thesis/Hardangervidda/Dates/',\n",
    "    'date' : '20200306',\n",
    "    #'DEM': 'C:/Users/Rasmu/Documents/Thesis/DEM/ArcticDEM_10m.tif',\n",
    "    'DEM': 'C:/Users/Rasmu/Documents/Thesis/DEM/mergedDEM10m_Hardanger.tif'\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
